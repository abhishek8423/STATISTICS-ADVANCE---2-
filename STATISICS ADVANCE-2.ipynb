{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65eacb54-7c2b-4494-b5b3-b8c9d4dcbda0",
   "metadata": {},
   "source": [
    "# __STATISTICS ADVANCE - 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80363c95-3c01-4fa9-833b-705837927e4d",
   "metadata": {},
   "source": [
    "### Question1: Define the z-statistic and explain its relationship to the standard normal distribution. How is the z-statistic used in hypothesis testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881d6cc-4c61-40a9-a7c3-5e00fc4e0bfc",
   "metadata": {},
   "source": [
    "The **z-statistic** (or z-score) is a statistical measurement that describes the position of a data point in relation to the mean of a group of values, expressed in terms of standard deviations from the mean. It is calculated using the formula:\n",
    "\n",
    "\\[\n",
    "z = \\frac{(X - \\mu)}{\\sigma}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( X \\) is the value being evaluated,\n",
    "- \\( \\mu \\) is the mean of the population, and\n",
    "- \\( \\sigma \\) is the standard deviation of the population.\n",
    "\n",
    "The z-statistic tells us how many standard deviations a particular observation is from the population mean.\n",
    "\n",
    "### Relationship to the Standard Normal Distribution\n",
    "The standard normal distribution is a special type of normal distribution that has a mean of 0 and a standard deviation of 1. When data is converted to z-scores, it follows the standard normal distribution. This transformation allows for comparisons across different data sets with different scales, as all z-scores are interpreted relative to the same standard normal distribution.\n",
    "\n",
    "In a standard normal distribution:\n",
    "- Approximately 68% of the data falls within one standard deviation from the mean (z-scores between -1 and 1).\n",
    "- About 95% of the data falls within two standard deviations (z-scores between -2 and 2).\n",
    "- Roughly 99.7% of the data lies within three standard deviations (z-scores between -3 and 3).\n",
    "\n",
    "### Use of Z-Statistic in Hypothesis Testing\n",
    "The z-statistic is used in hypothesis testing to determine if there is enough evidence to reject a null hypothesis. In hypothesis testing:\n",
    "1. **Formulate Hypotheses**: The null hypothesis (\\( H_0 \\)) is a statement that there is no effect or difference, while the alternative hypothesis (\\( H_1 \\)) suggests the opposite.\n",
    "2. **Calculate the Z-Statistic**: Based on the sample data, calculate the z-score to measure how far the observed data deviates from the null hypothesis.\n",
    "3. **Compare with Critical Value**: The calculated z-statistic is compared to a critical value from the standard normal distribution (usually for a significance level like 0.05). If the absolute value of the z-statistic is greater than the critical value, the null hypothesis is rejected.\n",
    "4. **P-Value Approach**: Alternatively, the p-value corresponding to the z-statistic can be calculated to determine the probability of observing a result as extreme as, or more extreme than, the one obtained under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8322c7a-d97b-431d-ab85-adc1d6a1f4ff",
   "metadata": {},
   "source": [
    "### Question2 : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is very small (e.g., 0.01)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a49e8a-8d54-4562-ae58-cd1890dd27e3",
   "metadata": {},
   "source": [
    "A **p-value** is a probability that measures the strength of the evidence against the null hypothesis in hypothesis testing. It represents the probability of obtaining an observed result, or something more extreme, assuming that the null hypothesis (\\( H_0 \\)) is true. The p-value helps to decide whether to reject the null hypothesis in favor of the alternative hypothesis (\\( H_1 \\)).\r\n",
    "\r\n",
    "### Use of P-Value in Hypothesis Testing\r\n",
    "In hypothesis testing, the p-value is used as follows:\r\n",
    "1. **Formulate Hypotheses**: Define the null hypothesis (\\( H_0 \\)) and the alternative hypothesis (\\( H_1 \\)).\r\n",
    "2. **Set the Significance Level (\\( \\alpha \\))**: This is the threshold probability used to judge whether the p-value is sufficiently small. Common choices for \\( \\alpha \\) are 0.05, 0.01, or 0.10.\r\n",
    "3. **Calculate the P-Value**: Use the sample data to compute the p-value based on the test statistic (e.g., z-statistic, t-statistic).\r\n",
    "4. **Compare P-Value to Significance Level**: \r\n",
    "   - If the p-value is **less than or equal to \\( \\alpha \\)**, there is strong evidence against \\( H_0 \\), and the null hypothesis is rejected. This implies the observed effect is statistically significant.\r\n",
    "   - If the p-value is **greater than \\( \\alpha \\)**, there is insufficient evidence to reject \\( H_0 \\), suggesting that the observed effect could be due to random chance.\r\n",
    "\r\n",
    "### Interpretation of a Very Small P-Value (e.g., 0.01)\r\n",
    "If the p-value is very small, such as 0.01:\r\n",
    "- It indicates **strong evidence against the null hypothesis**. The likelihood of observing the result (or something more extreme) by random chance, if the null hypothesis is true, is only 1%.\r\n",
    "- In practical terms, when the p-value is less than the chosen significance level (e.g., 0.05 or 0.01), we reject the null hypothesis and conclude that the observed effect is statisticalltider the effect size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3a9cd-8b58-4650-af4b-5336c1780a74",
   "metadata": {},
   "source": [
    "### Question3: Compare and contrast the binomial and Bernoulli distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe9754-57a4-401f-8d56-b8141ac8e8f7",
   "metadata": {},
   "source": [
    "The **binomial distribution** and the **Bernoulli distribution** are both discrete probability distributions that describe the outcomes of experiments involving binary events (i.e., events with two possible outcomes, such as success/failure or yes/no). However, they differ in terms of their applications, parameters, and properties.\r\n",
    "\r\n",
    "### Bernoulli Distribution\r\n",
    "- **Definition**: The Bernoulli distribution describes a single experiment (or trial) with two possible outcomes: \"success\" (usually coded as 1) and \"failure\" (coded as 0).\r\n",
    "- **Parameters**: It has one parameter, \\( p \\), which represents the probability of success. The probability of failure is \\( 1 - p \\).\r\n",
    "- **Probability Mass Function (PMF)**:\r\n",
    "  \r\n",
    "  \\[\r\n",
    "  P(X = x) = \r\n",
    "  \\begin{cases}\r\n",
    "  p, & \\text{if } x = 1\\\\\r\n",
    "  1 - p, & \\text{if } x = 0\r\n",
    "  \\end{cases}\r\n",
    "  \\]\r\n",
    "\r\n",
    "- **Mean**: The mean of a Bernoulli random variable is \\( p \\).\r\n",
    "- **Variance**: The variance is \\( p(1 - p) \\).\r\n",
    "- **Applications**: It is used to model individual binary outcomes, such as flipping a coin once, passing or failing an exam, or determining whether a product is defective.\r\n",
    "\r\n",
    "### Binomial Distribution\r\n",
    "- **Definition**: The binomial distribution describes the number of successes in a fixed number of independent Bernoulli trials, where each trial has the same probability of success.\r\n",
    "- **Parameters**: It has two parameters: \\( n \\), the number of trials, and \\( p \\), the probability of success in each trial.\r\n",
    "- **Probability Mass Function (PMF)**:\r\n",
    "  \r\n",
    "  \\[\r\n",
    "  P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\r\n",
    "  \\]\r\n",
    "\r\n",
    "  where \\( k \\) is the number of successes, and \\( \\binom{n}{k} \\) is the binomial coefficient.\r\n",
    "- **Mean**: The mean of a binomial random variable is \\( np \\).\r\n",
    "- **Variance**: The variance is \\( np(1 - p) \\).\r\n",
    "- **Applications**: It is used to model the number of successes in multiple trials, such as the number of heads in 10 coin flips, the number of defective items in a batch of 100, or the number of patients recthe binomial distribution with a single trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c41d2-79f1-4fce-828e-f8a26ef93492",
   "metadata": {},
   "source": [
    "### Question 4: Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41560920-55e2-462e-919b-07df52d16c0b",
   "metadata": {},
   "source": [
    "The **binomial distribution** is used under specific conditions where the following criteria are met:\r\n",
    "\r\n",
    "### Conditions for Using the Binomial Distribution:\r\n",
    "1. **Fixed Number of Trials (n)**: The experiment consists of a fixed number of trials, denoted by \\( n \\).\r\n",
    "2. **Binary Outcomes**: Each trial has only two possible outcomes, typically referred to as \"success\" and \"failure.\" These outcomes are mutually exclusive.\r\n",
    "3. **Constant Probability of Success (p)**: The probability of success, denoted by \\( p \\), remains the same for each trial.\r\n",
    "4. **Independence of Trials**: The outcome of any one trial does not affect the outcomes of other trials. Each trial is independent.\r\n",
    "\r\n",
    "### Examples of Situations that Meet These Conditions:\r\n",
    "- Flipping a coin \\( n \\) times and counting the number of heads (success).\r\n",
    "- Testing \\( n \\) light bulbs to see how many are defective (failure).\r\n",
    "- Conducting a survey where each respondent answers \"yes\" (success) or \"no\" (failure).\r\n",
    "\r\n",
    "### Relationship Between the Binomial and Bernoulli Distributions:\r\n",
    "- The **Bernoulli distribution** is essentially a special case of the **binomial distribution** where the number of trials \\( n = 1 \\). In other words, a Bernoulli trial is a binomial experiment with only one trial.\r\n",
    "- When using the binomial distribution, we are interested in the **total number of successes** across multiple independent Bernoulli trials.\r\n",
    "- The binomial distribution can be thought of as the sum of \\( n \\) independent and identically distributed Bernoulli rarepeated binary experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ad815-76a3-4e09-bf0f-e9c219aafc2f",
   "metadata": {},
   "source": [
    "### Question5: What are the key properties of the Poisson distribution, and when is it appropriate to use this distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5834c4-d130-494e-9646-5fb4ba204ea1",
   "metadata": {},
   "source": [
    "The **Poisson distribution** is a probability distribution that models the number of times an event occurs within a fixed interval of time, space, or any other continuous domain. It is used when events happen independently, and the rate at which they occur is constant. Here are its key properties and appropriate use cases:\n",
    "\n",
    "### Key Properties of the Poisson Distribution:\n",
    "1. **Discrete Distribution**: The Poisson distribution is discrete, meaning it counts the number of occurrences (0, 1, 2, ...) of an event in a fixed interval.\n",
    "\n",
    "2. **Parameter (λ)**: It is characterized by a single parameter, \\( \\lambda \\), which represents both the **mean** and the **variance** of the distribution. \\( \\lambda \\) is the average number of occurrences in the interval.\n",
    "   - **Mean**: \\( E(X) = \\lambda \\)\n",
    "   - **Variance**: \\( \\text{Var}(X) = \\lambda \\)\n",
    "\n",
    "3. **Probability Mass Function (PMF)**:\n",
    "   The probability of observing exactly \\( k \\) events (where \\( k \\) is a non-negative integer) is given by:\n",
    "   \\[\n",
    "   P(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n",
    "   \\]\n",
    "   where \\( e \\) is the base of the natural logarithm (approximately 2.718).\n",
    "\n",
    "4. **Memorylessness Property**: The Poisson distribution has the memoryless property when applied to time between events, meaning the probability of an event occurring in the future does not depend on the past.\n",
    "\n",
    "### When to Use the Poisson Distribution:\n",
    "- **Counting the Number of Events in a Time Period**: For example, the number of customer arrivals at a store per hour, the number of phone calls received by a call center in a day, or the number of emails received in an hour.\n",
    "- **Modeling Spatial Occurrences**: Such as the number of defects in a certain length of material, or the number of trees in a given area.\n",
    "- **Rare Events in a Large Population**: The Poisson distribution can approximate the binomial distribution when the number of trials \\( n \\) is large, and the probability of success \\( p \\) is small (with \\( np \\approx \\lambda \\)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6565b5-df17-4167-8eec-354f57a44727",
   "metadata": {},
   "source": [
    "### Question6: Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a PDF differ from a probability mass function (PMF)??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe9934-28fd-4eb1-b1e3-8fadd162c4b2",
   "metadata": {},
   "source": [
    "### Probability Distribution\r\n",
    "A **probability distribution** is a function that describes how probabilities are assigned to different possible outcomes of a random variable. It shows the likelihood of each possible value that a random variable can take. Probability distributions can be either:\r\n",
    "1. **Discrete**, where the random variable takes on specific, countable values.\r\n",
    "2. **Continuous**, where the random variable can take on an infinite number of values within a given range.\r\n",
    "\r\n",
    "### Probability Density Function (PDF)\r\n",
    "A **Probability Density Function (PDF)** is used to describe the probability distribution of a **continuous random variable**. The PDF, denoted by \\( f(x) \\), represents the relative likelihood of the random variable taking on a particular value. Key properties of a PDF include:\r\n",
    "- The probability that the random variable falls within a specific interval \\( [a, b] \\) is given by the area under the PDF curve between \\( a \\) and \\( b \\):\r\n",
    "  \\[\r\n",
    "  P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) \\, dx\r\n",
    "  \\]\r\n",
    "- The total area under the PDF curve across all possible values of the random variable equals 1:\r\n",
    "  \\[\r\n",
    "  \\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\r\n",
    "  \\]\r\n",
    "- The value of the PDF at a specific point does not represent the probability of that exact value (since the probability of a continuous random variable taking on a specific value is zero), but rather the density of probability near that value.\r\n",
    "\r\n",
    "### Probability Mass Function (PMF)\r\n",
    "A **Probability Mass Function (PMF)** is used for **discrete random variables**. It provides the probability that a discrete random variable is exactly equal to a specific value. For a random variable \\( X \\), the PMF is denoted as \\( P(X = x) \\), and it satisfies:\r\n",
    "- The sum of the probabilities over all possible values of \\( X \\) equals 1:\r\n",
    "  \\[\r\n",
    "  \\sum_{x} P(X = x) = 1\r\n",
    "  \\]\r\n",
    "- Each probability value \\( P(X =probability of each possible outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d82a5-af55-4b05-b3ae-988c53ca7169",
   "metadata": {},
   "source": [
    "### Question7: Explain the Central Limit Theorem (CLT) with example.\r\n",
    "\r\n",
    "\r\n",
    "\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca664d8-0606-4a2a-84a2-b6faff51514c",
   "metadata": {},
   "source": [
    "The **Central Limit Theorem (CLT)** is a fundamental concept in statistics that states that the distribution of the sample mean (or sum) of a large number of independent, identically distributed random variables approaches a **normal distribution**, regardless of the shape of the original population distribution. This approximation becomes more accurate as the sample size increases.\r\n",
    "\r\n",
    "### Key Points of the Central Limit Theorem:\r\n",
    "1. **Independent and Identically Distributed (i.i.d.) Random Variables**: The theorem applies to a set of random variables that are independent and drawn from the same probability distribution.\r\n",
    "2. **Sample Size (n)**: As the sample size \\( n \\) increases, the sampling distribution of the sample mean becomes closer to a normal distribution.\r\n",
    "3. **Mean and Standard Deviation**: If the original population has a mean \\( \\mu \\) and standard deviation \\( \\sigma \\), then the sampling distribution of the sample mean will have a mean of \\( \\mu \\) and a standard deviation (standard error) of \\( \\frac{\\sigma}{\\sqrt{n}\n",
    "4. ed sufficient).\r\n",
    "\r\n",
    "### Example of the Central Limit Theorem:\r\n",
    "Suppose you want to understand the average height of all adult men in a city. The population of heights is not normally distributed, but instead may be skewed or have outliers.\r\n",
    "\r\n",
    "1. **Step 1: Take Multiple Random Samples**  \r\n",
    "   Suppose you take several random samples of 50 men each and measure their heights.\r\n",
    "\r\n",
    "2. **Step 2: Calculate the Sample Mean for Each Sample**  \r\n",
    "   Compute the average height for each of the samples. Even though the original population is not normally distributed, the distribution of these sample means will tend to resemble a normal distribution.\r\n",
    "\r\n",
    "3. **Step 3: As Sample Size Increases, the Distribution Approaches Normality**  \r\n",
    "   As you take more samples, or increase the sample size (e.g., from 50 men to 100 men per sample), the distribution of the sample means will more closely approximate a normal distribution, regardless of the original shape dealing with non-normal populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736df6c-7f68-4e68-9819-bb69e8c213fe",
   "metadata": {},
   "source": [
    "### Question8: Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be  applied instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64851370-a059-4aaa-934f-c050c7e15818",
   "metadata": {},
   "source": [
    "Z-scores and t-scores are both standardized scores used in statistics to understand how a particular data point relates to the mean of a data set. However, they differ in their application and the contexts in which they are used. Here’s a comparison of the two:\n",
    "\n",
    "### Z-scores\n",
    "\n",
    "- **Definition**: A z-score indicates how many standard deviations a data point is from the mean of a distribution. It is calculated using the formula:\n",
    "  \\[\n",
    "  z = \\frac{(X - \\mu)}{\\sigma}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\( X \\) = value of the data point\n",
    "  - \\( \\mu \\) = mean of the population\n",
    "  - \\( \\sigma \\) = standard deviation of the population\n",
    "\n",
    "- **When to Use**:\n",
    "  - When the population standard deviation (\\( \\sigma \\)) is known.\n",
    "  - When the sample size is large (typically \\( n \\geq 30 \\)), allowing the use of the Central Limit Theorem to justify the normality of the sampling distribution.\n",
    "  - When dealing with data that is normally distributed or approximately normally distributed.\n",
    "\n",
    "- **Example**: Calculating z-scores is common in quality control processes where population parameters are known.\n",
    "\n",
    "### T-scores\n",
    "\n",
    "- **Definition**: A t-score also indicates how many standard deviations a data point is from the mean but is used when the sample size is small and/or the population standard deviation is unknown. It is calculated using the formula:\n",
    "  \\[\n",
    "  t = \\frac{(X - \\bar{X})}{(s/\\sqrt{n})}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\( X \\) = value of the data point\n",
    "  - \\( \\bar{X} \\) = sample mean\n",
    "  - \\( s \\) = sample standard deviation\n",
    "  - \\( n \\) = sample size\n",
    "\n",
    "- **When to Use**:\n",
    "  - When the population standard deviation is unknown.\n",
    "  - When the sample size is small (\\( n < 30 \\)).\n",
    "  - When the underlying population from which the sample is drawn is normally distributed or approximately normal.\n",
    "\n",
    "- **Example**: T-scores are often used in smaller studies or experiments in psychology and other fields where population parameters are not well-known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84add123-4e27-496a-a418-6eb515d15fec",
   "metadata": {},
   "source": [
    "### Question9: Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to reject the null hypothesis? Task: Write Python code to calculate the z-score and p-value for the given data. Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70592c28-1eb5-49fb-b53a-f57dd0b9148e",
   "metadata": {},
   "source": [
    "\r\n",
    "### Given Data\r\n",
    "- Sample Mean (\\( \\bar{X} \\)): 105\r\n",
    "- Population Mean (\\( \\mu \\)): 100\r\n",
    "- Standard Deviation (\\( \\sigma \\)): 15\r\n",
    "- Sample Size (\\( n \\)): 25\r\n",
    "- Significance Level (\\( \\alpha \\)): 0.05\r\n",
    "\r\n",
    "### Step 1: Calculate the Z-score\r\n",
    "The formula for the z-score is:\r\n",
    "\\[\r\n",
    "z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\r\n",
    "\\]\r\n",
    "Substituting the values:\r\n",
    "\\[\r\n",
    "z = \\frac{105 - 100}{\\frac{15}{\\sqrt{25}}} = \\frac{5}{3} \\approx 1.67\r\n",
    "\\]\r\n",
    "\r\n",
    "### Step 2: Calculate the P-value\r\n",
    "To find the p-value for a two-tailed test, we need to look up the z-score in the standard normal distribution. The p-value can be calculated using:\r\n",
    "\\[\r\n",
    "\\text{p-value} = 2 \\times (1 - \\text{CDF}(z))\r\n",
    "\\]\r\n",
    "Where CDF is the cumulative distribution function. \r\n",
    "\r\n",
    "Using a z-score of approximately 1.67:\r\n",
    "- The p-value can be calculated as follows:\r\n",
    "\\[\r\n",
    "\\text{p-value} \\approx 2 \\times (1 - \\text{CDF}(1.67))\r\n",
    "\\]\r\n",
    "\r\n",
    "### Step 3: Decision Rule\r\n",
    "- If the p-value is less than the significance level (\\( \\alpha = 0.05 \\)), we reject the null hypothesis.\r\n",
    "- If the p-value is greater than \\( \\alpha \\), we fail to reject the null hypothesis.\r\n",
    "\r\n",
    "### Calculation of the p-value\r\n",
    "Now, let’s calculate the p-value using the z-score. \r\n",
    "\r\n",
    "### Z-Score and P-Value Calculation\r\n",
    "Using the previously calculated z-score of \\( 1.67 \\):\r\n",
    "\r\n",
    "1. Calculate the cumulative probability for \\( z = 1.67 \\).\r\n",
    "2. Calculate the p-value.\r\n",
    "\r\n",
    "Let's calculate this in Python.\r\n",
    "\r\n",
    "### Results\r\n",
    "- **Z-score**: \\( 1.67 \\) (rounded to two decimal places)\r\n",
    "- **P-value**: \\( 0.0956 \\) (rounded to four decimal places)\r\n",
    "\r\n",
    "### Hypothesis Testing Decision\r\n",
    "Given a significance level (\\( \\alpha \\)) of 0.05:\r\n",
    "\r\n",
    "1. **Null Hypothesis (\\( H_0 \\))**: The population mean is equal to 100.\r\n",
    "2. **Alternative Hypothesis (\\( H_a \\))**: The population mean is not equal to 100.\r\n",
    "\r\n",
    "### Decision Rule\r\n",
    "- If the p-value is less than the significance level (\\( \\alpha = 0.05 \\)), we reject the null hypothesis.\r\n",
    "- If the p-value is greater than the  that the population mean differs from 100 based on this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7696b47e-c45c-4bfd-ac10-f383177892b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 1.67\n",
      "P-value: 0.0956\n",
      "Fail to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "sample_mean = 105            \n",
    "population_mean = 100       \n",
    "standard_deviation = 15      \n",
    "sample_size = 25             \n",
    "alpha = 0.05                 \n",
    "\n",
    "# Step 1: Calculate the z-score\n",
    "z_score = (sample_mean - population_mean) / (standard_deviation / (sample_size ** 0.5))\n",
    "\n",
    "# Step 2: Calculate the p-value (two-tailed)\n",
    "p_value = 2 * (1 - stats.norm.cdf(z_score))\n",
    "print(f\"Z-score: {z_score:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 3: Decision based on the p-value\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63808ca1-b7c8-4f9d-95d3-92e4febe119d",
   "metadata": {},
   "source": [
    "Question10: Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python.Generate 1,000 samples and plot the distribution. What is the expected mean and variance Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.Objective: Understand the properties of a binomial distribution and verify them through simulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
